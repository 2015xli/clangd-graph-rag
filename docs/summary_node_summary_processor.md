# NodeSummaryProcessor: Design and Architecture

## 1. High-Level Role

The `NodeSummaryProcessor` is the stateless **"logic layer"** or **"brain"** of the RAG generation process. It encapsulates all the intelligence for processing a single node. Its purpose is to be a pure computation engine, receiving all necessary data from a worker thread, performing the complex decision-making and LLM interaction, and returning a result packet containing a `status` and `data`.

This class does **not** interact with the Neo4j database directly. Its only stateful interaction is read-only access to the `SummaryCacheManager` to check the status of dependencies and retrieve cached summaries.

## 2. Core Architectural Principle: The "Waterfall" Decision Process

The core of the `NodeSummaryProcessor` is a consistent, sequential decision-making pattern implemented in each of its `get_*_summary` methods. This "waterfall" logic ensures that work is done in the most efficient way possible, preferring cheaper, existing data sources before falling back to expensive LLM calls.

The process for each node is as follows:

1.  **Check for "Perfect" State (DB Hit)**: The processor first checks if the node is **not stale** and **already has a valid summary in the database**. If both are true, this is the ideal "unchanged" state. It immediately returns an `unchanged` status with the existing database summary.

2.  **Check for "Restorable" State (Cache Hit)**: If the node is not in a perfect state, the processor then checks if it is **not stale** but a **valid summary exists in the cache**. This happens when the database is missing a summary that was generated in a previous run. If a valid, non-empty summary is found in the cache, it returns a `summary_restored` status. This tells the orchestrator to write the value to the database but **not** to flag it as a change that would trigger upstream updates.

3.  **Fallback to Regeneration (LLM Call)**: If neither of the above conditions is met, it means the node is either **stale** (its dependencies changed) or it has **no valid summary anywhere**. In this case, the processor *must* regenerate the summary.
    *   It gathers the necessary context (e.g., summaries of child nodes) by reading from the `SummaryCacheManager`.
    *   It constructs a detailed prompt using `RagGenerationPromptManager`.
    *   It calls the `LlmClient` to get a new summary.
    *   If successful, it returns a `summary_regenerated` status with the new summary data.

## 3. Statuses and Error Handling

The processor returns one of several statuses to inform the orchestrator of the outcome:

*   `unchanged`: No work was needed, or a benign failure occurred (e.g., no child summaries were available to generate a parent summary). The orchestrator will not update the cache with empty data.
*   `summary_restored` / `code_analysis_restored`: A valid summary was found in the cache and should be written to the database to fill a gap. This does **not** trigger upstream dependency updates.
*   `summary_regenerated` / `code_analysis_regenerated`: A new summary was successfully generated by the LLM. This **does** trigger upstream dependency updates.
*   `generation_failed`: A hard error occurred during generation (e.g., the LLM call failed). This signals a problem but allows the run to continue without corrupting data. The orchestrator will not update the cache.

## 4. Key Methods and Workflows

### `get_function_code_analysis(node_data)`

This is the first pass and its logic is based on content hashing.
1.  It computes a new MD5 hash of the function's source code.
2.  If the new hash matches the `db_code_hash` and a `db_code_analysis` exists, it returns `unchanged`.
3.  If the DB is stale, it checks the cache for an entry matching the **new** hash. If found, it returns `code_analysis_restored`.
4.  If both fail, it generates a new `code_analysis` via LLM and returns `code_analysis_regenerated`, or `generation_failed` if the LLM call fails.

### `get_function_contextual_summary`, `get_class_summary`, etc.

All other hierarchical and contextual summary methods now follow the robust "waterfall" logic described in Section 2.

*   **Staleness Check**: Each method first determines if a node is stale by checking the `runtime_status` of its specific dependencies (e.g., parent classes, child methods, callers/callees) in the `SummaryCacheManager`.
*   **Context Gathering**: During the regeneration step, these methods are careful to gather context summaries (e.g., `parent_summaries`, `method_summaries`) from the cache. The logic now robustly filters out any `None` or empty string values to prevent errors during prompt construction.
*   **Return Values**: They return `unchanged`, `summary_restored`, or `summary_regenerated`/`generation_failed` based on the outcome of the waterfall decision process.

## 5. Iterative Summarization for Large Contexts

A key feature of the `NodeSummaryProcessor` is its ability to handle contexts that exceed the LLM's token limit.

*   **Mechanism**: Before making an LLM call, the processor first calculates the total token count of the context. If it's over the limit, it uses helper methods (`_analyze_function_text_iteratively`, `_summarize_relations_iteratively`) to chunk the context and process it sequentially, feeding the output of one LLM call as input to the next.
*   **Benefit**: This makes the summarization process resilient and capable of handling arbitrarily large functions or complex classes without crashing or losing information.