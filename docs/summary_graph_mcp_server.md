# Summary: `graph_mcp_server.py` - AI Agent Tool Server

## 1. High-Level Role

The `graph_mcp_server.py` script provides a practical example of how to leverage the generated code graph for advanced, AI-driven tasks. It implements a **Model Context Protocol (MCP)** server that exposes the Neo4j graph database as a set of queryable **tools** for an AI agent.

In essence, this server acts as the bridge between a large language model and the rich, structured data of the code graph. It allows an AI agent to "ask questions" about the codebase by calling these tools, enabling sophisticated workflows like automated code analysis, impact assessment, and complex query answering.

## 2. Core Architecture

*   **Framework**: The server is built using the `fastmcp` library, which simplifies the process of creating tool-serving APIs for AI models. The underlying web server is `uvicorn`.
*   **Database Connection**: On startup, the server initializes a persistent connection to the Neo4j database using the project's `Neo4jManager`.
*   **Project Path Discovery**: A critical function on startup is discovering the project's absolute root path. It does this by querying the `:PROJECT` node in the graph. This is essential because the graph stores relative file paths, and the server needs the root path to construct absolute paths for reading source code from disk.

## 3. Provided Tools for the AI Agent

The server exposes a set of functions as tools that an AI agent can call. These tools provide the agent with the necessary capabilities to explore and understand the codebase.

### `get_graph_schema()`
*   **Purpose**: To retrieve the schema of the Neo4j graph.
*   **Functionality**: This tool provides the agent with a description of all node labels (e.g., `:FUNCTION`, `:CLASS_STRUCTURE`), their properties (e.g., `name`, `summary`), and the relationships between them (e.g., `[:CALLS]`, `[:INHERITS]`).
*   **Agent Use Case**: This is often the first tool an agent calls. It's equivalent to the agent reading the API documentation for the graph, allowing it to learn how to formulate meaningful queries.

### `get_project_info()`
*   **Purpose**: To get a high-level overview of the project.
*   **Functionality**: It queries the `:PROJECT` node to retrieve its name, root path, and the top-level summary generated by the RAG process.
*   **Agent Use Case**: This gives the agent its initial context, answering the question "What project am I looking at?".

### `get_source_code(node_id: str)`
*   **Purpose**: To retrieve the source code for a specific code entity.
*   **Functionality**: Given the unique ID of a node (e.g., a `:FUNCTION` or `:CLASS_STRUCTURE`), this tool queries the graph to find the entity's file path and its precise `body_location` (start and end lines). It then reads this specific slice of the file from disk and returns the source code. If no `body_location` is available, it returns the content of the entire file.
*   **Agent Use Case**: This is a fundamental tool for any deep code analysis. After finding a relevant function via a query, the agent uses this tool to read its source code for summarization, bug detection, or refactoring analysis.

### `execute_cypher_query(query: str)`
*   **Purpose**: To execute a direct, read-only Cypher query against the graph.
*   **Functionality**: This is the most powerful and flexible tool. It allows the agent to perform complex graph traversals and ask nuanced questions that are not covered by the other tools.
*   **Security**: The tool includes a crucial safety check that blocks any query containing write keywords (e.g., `CREATE`, `SET`, `DELETE`), ensuring the agent can only read from the database.
*   **Agent Use Case**: An agent could use this to find all functions that call a specific, deprecated function (`MATCH (caller)-[:CALLS]->(callee) WHERE callee.name = 'deprecated_func' RETURN caller.name`), or to trace the inheritance chain of a class.

## 4. Usage

The server can be started by running the script directly:
```bash
python3 graph_mcp_server.py
```
This will launch the `uvicorn` server, making the tools available for an AI agent to connect to and use.
