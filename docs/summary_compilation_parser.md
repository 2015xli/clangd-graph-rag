# Algorithm Summary: `compilation_parser.py`

## 1. Role in the Pipeline

This module provides the low-level, "raw" parsing strategies for C/C++ source code. It was created as part of a major refactoring to separate the concerns of parsing from the concerns of caching and orchestration. 

Its sole responsibility is to parse a given list of source files and extract several key pieces of information:
1.  The precise locations (spans) of symbol definitions (e.g., functions, classes, structs, templates).
2.  The ground-truth definitions of preprocessor **Macros** (`#define`).
3.  Comprehensive information for **Type Aliases** (`typedef` and `using`), including their aliased types.
4.  The set of all `#include` relationships.
5.  **Causality metadata** for macro-expanded symbols (the original invocation text and the source macro).

This module acts as the "worker" layer, providing concrete parsing implementations that are managed by the `CompilationManager`.

## 2. Core Design: The Strategy Pattern

The module is designed using the Strategy pattern to allow for flexible switching between different parsing engines. 

*   **`CompilationParser` (Abstract Base Class)**: Defines the common interface that all concrete strategies must implement. This includes methods like `parse()`, `get_source_spans()`, `get_type_alias_spans()`, `get_macro_spans()`, and `get_include_relations()`.
*   **Kind-Aware Synthetic IDs**: The `make_symbol_key` and `make_synthetic_id` methods now include the symbol **kind** (e.g., `"Struct::my_name::..."`). This is critical to prevent ID collisions when different entity types (like an anonymous struct and its typedef) share the same source location due to macro expansion.

## 3. Concrete Strategy: `ClangParser`

This is the primary and recommended strategy, valued for its accuracy.

*   **Technology**: It uses `clang.cindex`, the official Python bindings for `libclang`.
*   **Semantic Accuracy**: Its key advantage is that it is **semantically aware**. By using a `compile_commands.json` file, it parses source code with the exact same context as the compiler. This allows it to correctly interpret complex macros, accurately identify a wide range of C++ constructs, and resolve the underlying types of aliases.
*   **Detailed Preprocessing Record**: The parser uses `PARSE_DETAILED_PROCESSING_RECORD` to preserve macro definitions and instantiations in the AST, which are normally stripped before AST construction.
*   **Macro Causality Tracking**: The parser tracks `MACRO_INSTANTIATION` cursors to identify symbols generated by macros. For such symbols, it extracts the `original_name` (the raw invocation text, e.g., `DECLARE_MODULE(FS)`) and links them to the source macro via an `expanded_from_id`.
*   **Dual Extraction**: For efficiency, the parser traverses the Abstract Syntax Tree (AST) of each source file once, extracting both symbol definition spans and include relationships in a single pass.
*   **Path Handling**: A critical implementation detail is that it temporarily changes the working directory (`os.chdir`) to the compilation directory specified in `compile_commands.json` for each file it parses. This is essential for `libclang` to correctly resolve any relative include paths. This operation is safely wrapped in a `try...finally` block to guarantee the original working directory is always restored.
*   **Parallel Processing with Flow Control and Batching**: The `ClangParser` leverages `concurrent.futures.ProcessPoolExecutor` to parse multiple Translation Units (TUs) in parallel, incorporating significant memory optimizations:
    *   **"Spawn" Context**: The `ProcessPoolExecutor` is initialized with `multiprocessing.get_context("spawn")`. This ensures that worker processes start as fresh Python interpreters, avoiding memory inheritance from the potentially large main process and reducing overall memory footprint.
    *   **Throttled Submission**: Instead of submitting all tasks at once, the main process maintains a limited number of "in-flight" tasks (e.g., `num_workers * 2`). It uses `wait(futures, return_when=FIRST_COMPLETED)` to wait for any worker to complete a task. As soon as a result is received, a new task is submitted to keep the worker pool busy without overwhelming the main process's result queue. This prevents memory bottlenecks in the main process.
    *   **Task Batching for Workers**: Tasks are dispatched to workers in batches (controlled by `batch_size`, defaulting to 1). The `_parallel_worker` function now accepts a list of compilation entries (a batch). If a batch contains multiple entries, the worker process performs local parsing and merging of results from these multiple TUs within the batch before sending a single combined result back to the main process. This was intended to reduce the main process's merging overhead, though current tests show no significant performance improvement when `batch_size` is greater than 1. The feature is retained for potential future use or different scenarios.
    *   The `items_to_process` (list of compilation entries) is treated as an iterator, allowing items to be pulled one by one, avoiding loading all items into memory at once.
*   **Header Caching (`_global_header_cache` and `_tu_hash`)**: To prevent redundant parsing of header files across different TUs, `_ClangWorkerImpl` implements a sophisticated caching mechanism:
    *   A `_tu_hash` is computed for each TU based on its compilation arguments (preprocessor macros, include paths, language dialect). This hash uniquely identifies the compilation environment. The `_get_tu_hash` logic has been improved to bucket flags into categories (Language, Macros, Features, Includes, Other) and preserve relative order within buckets, ensuring more robust cache collision avoidance.
    *   A `_global_header_cache` (shared across worker processes) stores header file paths that have already been fully processed for a given `_tu_hash`.
    *   When a worker encounters a header file during AST traversal, it checks if that header has already been processed under the *exact same `_tu_hash`*. If so, parsing of that header's AST is safely skipped, as the `SourceSpan` data would be identical. This significantly reduces redundant work.
    *   A `_local_header_cache` temporarily collects headers processed by the current TU before merging them into the `_global_header_cache` at the end of the TU's processing.
*   **Node Deduplication**: Within a single TU's AST traversal, the `_process_generic_node` method uses a `node_key` (derived from symbol name, file URI, line, and column) to ensure that only one `SourceSpan` object is created and stored for each unique AST node. This prevents duplicate entries if `libclang` reports the same node multiple times.
*   **Argument Sanitization**: The `_sanitize_args` method has been refined to remove more irrelevant flags (e.g., `-W`, `-O`, `--`) from compilation arguments, further improving the determinism and effectiveness of the `_tu_hash`.

### 3.1. Output Data Structure: `SourceSpan` and `source_spans`

The primary output of the `ClangParser` is a collection of `SourceSpan` objects, organized in the `self.source_spans` dictionary:

*   **`self.source_spans`**: `Dict[file_uri, Dict[node_key, SourceSpan]]`
    *   The outer dictionary maps the absolute file URI (e.g., `file:///path/to/file.cpp`) to an inner dictionary.
    *   The inner dictionary maps a unique `node_key` (e.g., `kind::name::file_uri:line:col`) to a `SourceSpan` object.
*   **`SourceSpan` (dataclass)**: Represents a lexically defined entity in the source code. It contains:
    *   `name`: The name of the entity.
    *   `kind`: The type of entity (e.g., "Function", "Class").
    *   `lang`: The programming language ("C" or "Cpp").
    *   `name_location`: A `RelativeLocation` object for the entity's name.
    *   `body_location`: A `RelativeLocation` object for the entire body of the entity.
    *   `id`: A deterministic `synthetic_id` generated from the kind-aware `node_key`.
    *   `parent_id`: The `synthetic_id` of the immediate lexical parent.
    *   **`original_name`**: The raw macro invocation text if generated by a macro.
    *   **`expanded_from_id`**: The synthetic ID of the macro that generated this symbol.

### 3.2. Output Data Structure: `TypeAliasSpan`

*   **`TypeAliasSpan` (dataclass)**: Stores comprehensive info for `typedef` and `using` declarations.
    *   Includes `aliased_canonical_spelling`, `aliased_type_id`, and `aliased_type_kind` to resolve the underlying type.
    *   Like `SourceSpan`, it supports `original_name` and `expanded_from_id` for macro-generated aliases.

### 3.3. Output Data Structure: `MacroSpan`

*   **`MacroSpan` (dataclass)**: Represents a `#define` directive.
    *   `macro_definition`: The full source text of the macro directive.
    *   `is_function_like`: Distinguishes object-like from function-like macros.

### 3.4. Output Data Structure: `include_relations`

*   **`self.include_relations`**: `Set[IncludeRelation]`
    *   A set of `IncludeRelation` NamedTuple objects, where each tuple `(source_file, included_file)` represents a direct `#include` directive found during parsing. This uses `sys.intern` for string deduplication.

## 4. Concrete Strategy: `TreesitterParser`

This strategy is **currently not used** in the pipeline due to its limitations in accurately integrating with clangd indexed symbols.

*   **Technology**: It uses the `tree-sitter` library for purely syntactic parsing.
*   **Pros and Cons**: It is significantly faster than the `ClangParser` but is not semantically aware. It can be easily fooled by functions or signatures defined with complex preprocessor macros.
*   **Key Limitation**: This parser is only capable of extracting function spans. Its `get_include_relations()` method returns an empty data structure. Therefore, it **cannot be used** for the robust, include-based dependency analysis required by the incremental updater.
